---
layout: post
title: Day 2 of '#100DaysofCode'
---

Day 2 and I'm already all over the place, this is more of a "figure it out as you go along" sort of endeavor. I mentioned last post I wanted to learn a little about Apache Spark, and Hadoop MapReduce because that's essentially what Spark replaced in industry. 

I've done enough prior research to know Apache Spark is this sort of **Big Data** processing engine. The vital difference between it and MapReduce is that it processes data in real-time, and there's multiple machines, (aka 'clusters'), working together to process this high amount of data. 











